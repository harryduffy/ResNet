{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMN/U2XY8EO445CW54lKjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryduffy/ResNet/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers.legacy import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation, add, concatenate\n",
        "from tensorflow.keras import layers, models\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/Road Extraction/Duffy/ResNet/')\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from util import load_data, preprocess_data\n",
        "# from res_unet import build_res_unet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5ZMPXC1w9SV",
        "outputId": "5265444a-c242-4f39-a7c2-d43ee655c533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters):\n",
        "    shortcut = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Add the shortcut to the output of the convolution block\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(x, filters):\n",
        "    x = residual_block(x, filters)\n",
        "    p = layers.MaxPooling2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(x, skip, filters):\n",
        "    x = layers.Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.concatenate([x, skip])\n",
        "    x = residual_block(x, filters)\n",
        "    return x\n",
        "\n",
        "def build_res_unet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    # Bridge\n",
        "    b1 = residual_block(p4, 1024)\n",
        "\n",
        "    # Decoder\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(d4)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "LkvkZzRPmPYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i45KOFwVwTV6",
        "outputId": "375140e4-aff4-4405-d4be-0fda4f8dcf03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Memory growth set for GPU.\n",
            "3236\n"
          ]
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    print('GPU is available:', physical_devices)\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "        print('Memory growth set for GPU.')\n",
        "    except Exception as e:\n",
        "        print(f'Error setting memory growth: {e}')\n",
        "else:\n",
        "    print('GPU is not available')\n",
        "\n",
        "\n",
        "# initialize input size and shape\n",
        "INPUT_SIZE = (256, 256)\n",
        "INPUT_SHAPE = (256, 256, 3) # color images, 3 channels\n",
        "\n",
        "def display_data(dir_path, image_paths, mask_paths):\n",
        "\n",
        "    fig, axes = plt.subplots(5, 2, figsize=(10, 15))\n",
        "\n",
        "    # Iterate over the image and mask pairs and display them in subplots\n",
        "    for i, (image_path, mask_path) in enumerate(zip(image_paths, mask_paths)):\n",
        "        # Load the image and mask using your preferred method\n",
        "        image = plt.imread(dir_path + image_path)\n",
        "        mask = plt.imread(dir_path + mask_path)\n",
        "\n",
        "        # Plot the image and mask in the corresponding subplot\n",
        "        axes[i, 0].imshow(image)\n",
        "        axes[i, 0].set_title('Image')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(mask)\n",
        "        axes[i, 1].set_title('Mask')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "    # Adjust the spacing between subplots\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('samples.png', bbox_inches='tight')  # Save as PNG image\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "# load data\n",
        "\n",
        "dir_path = '/content/drive/MyDrive/Road Extraction/Duffy/tiles/'\n",
        "image_filenames, mask_filenames = load_data(dir_path)\n",
        "\n",
        "print(len(image_filenames))\n",
        "\n",
        "# display the first 5 pairs of image and mask\n",
        "# random_indices = random.choices(range(0, len(image_filenames)), k=5)\n",
        "# display_data(dir_path, image_filenames[random_indices], mask_filenames[random_indices])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data (BBBRRRRRRT)\n",
        "with tf.device(\"/device:GPU:0\"):\n",
        "    images, masks = preprocess_data(dir_path, image_filenames, mask_filenames, input_size=INPUT_SIZE, augmented=False)"
      ],
      "metadata": {
        "id": "rSnnMOyLzqDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get shape of the image and mask\n",
        "print('Shape of image data: ' + str(images.shape))\n",
        "print('Shape of mask data: ' + str(masks.shape))\n",
        "\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "train_images, test_images, train_masks, test_masks = train_test_split(train_images, train_masks, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9H-3ZJz0m2F",
        "outputId": "c9a072ca-b83a-4fd9-fffe-09a1c9f527c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of image data: (3236, 256, 256, 3)\n",
            "Shape of mask data: (3236, 256, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise the model and get a summary\n",
        "model = build_res_unet(INPUT_SHAPE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwfzYaAC0tTX",
        "outputId": "a4681b86-be8d-49d1-d064-61d121c7a1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 256, 256, 64)         1792      ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 256, 256, 64)         256       ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 256, 256, 64)         256       ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 256, 256, 64)         256       ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 256, 256, 64)         256       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 256, 256, 64)         0         ['batch_normalization_28[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 256, 256, 64)         0         ['add_10[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 64)         0         ['activation_17[0][0]']       \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 128, 128, 128)        512       ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 128, 128, 128)        8320      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 128, 128, 128)        512       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 128, 128, 128)        512       ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 128, 128, 128)        0         ['batch_normalization_31[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 128, 128, 128)        0         ['add_11[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 128)          0         ['activation_19[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 64, 64, 256)          1024      ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 64, 64, 256)          33024     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 64, 64, 256)          1024      ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 64, 64, 256)          1024      ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 64, 64, 256)          0         ['batch_normalization_34[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 64, 64, 256)          0         ['add_12[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)          0         ['activation_21[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 32, 32, 512)          2048      ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 32, 32, 512)          131584    ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 32, 32, 512)          2048      ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 32, 32, 512)          2048      ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 32, 32, 512)          0         ['batch_normalization_37[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 32, 32, 512)          0         ['add_13[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 512)          0         ['activation_23[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 16, 16, 1024)         0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 16, 16, 1024)         9438208   ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 16, 16, 1024)         525312    ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 16, 16, 1024)         4096      ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 16, 16, 1024)         0         ['batch_normalization_40[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 16, 16, 1024)         0         ['add_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 32, 32, 512)          2097664   ['activation_25[0][0]']       \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 32, 32, 1024)         0         ['conv2d_transpose[0][0]',    \n",
            " )                                                                   'activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 32, 32, 512)          4719104   ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 32, 32, 512)          2048      ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 32, 32, 512)          0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 32, 32, 512)          2359808   ['activation_26[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 32, 32, 512)          524800    ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 32, 32, 512)          2048      ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 32, 32, 512)          2048      ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_15 (Add)                (None, 32, 32, 512)          0         ['batch_normalization_43[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 32, 32, 512)          0         ['add_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 64, 64, 256)          524544    ['activation_27[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 64, 64, 512)          0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 64, 64, 256)          1179904   ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 64, 64, 256)          1024      ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 64, 64, 256)          0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 64, 64, 256)          590080    ['activation_28[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 64, 64, 256)          131328    ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 64, 64, 256)          1024      ['conv2d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 64, 64, 256)          1024      ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 64, 64, 256)          0         ['batch_normalization_46[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 64, 64, 256)          0         ['add_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 128, 128, 128)        131200    ['activation_29[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 128, 128, 256)        0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   'activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 128, 128, 128)        295040    ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 128, 128, 128)        512       ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 128, 128, 128)        0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 128, 128, 128)        147584    ['activation_30[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 128, 128, 128)        32896     ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 128, 128, 128)        512       ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 128, 128, 128)        512       ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 128, 128, 128)        0         ['batch_normalization_49[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 128, 128, 128)        0         ['add_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 256, 256, 64)         32832     ['activation_31[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 256, 256, 128)        0         ['conv2d_transpose_3[0][0]',  \n",
            " )                                                                   'activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 256, 256, 64)         73792     ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 256, 256, 64)         256       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 256, 256, 64)         0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 256, 256, 64)         36928     ['activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 256, 256, 64)         8256      ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 256, 256, 64)         256       ['conv2d_54[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 256, 256, 64)         256       ['conv2d_52[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 256, 256, 64)         0         ['batch_normalization_52[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 256, 256, 64)         0         ['add_18[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 256, 256, 1)          65        ['activation_33[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32462849 (123.84 MB)\n",
            "Trainable params: 32445185 (123.77 MB)\n",
            "Non-trainable params: 17664 (69.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Define functions for evaluation metrics\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "    dice = K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n",
        "    return dice\n",
        "\n",
        "def iou(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n",
        "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "    return iou\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    precision = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) / (K.sum(K.round(K.clip(y_pred, 0, 1))) + K.epsilon())\n",
        "    recall = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) / (K.sum(K.round(K.clip(y_true, 0, 1))) + K.epsilon())\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1"
      ],
      "metadata": {
        "id": "dpLl25dNoEhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('models/save_best.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "# Compile model with custom metrics\n",
        "learning_rate = 0.0001\n",
        "model.compile(optimizer=RMSprop(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy', dice_coef, iou, f1_score])\n",
        "\n",
        "# Train the model while monitoring custom metrics\n",
        "epochs = 25\n",
        "history = model.fit(train_images, train_masks, batch_size=16, epochs=epochs, validation_data=(val_images, val_masks),callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_qAFGpyCoNfb",
        "outputId": "73a6e706-d245-4dd6-b677-f67efbd793d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.9245 - dice_coef: 0.0545 - iou: 0.0287 - f1_score: 0.0123\n",
            "Epoch 1: val_loss improved from inf to 0.20153, saving model to models/save_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r130/130 [==============================] - 251s 2s/step - loss: 0.2619 - accuracy: 0.9245 - dice_coef: 0.0545 - iou: 0.0287 - f1_score: 0.0123 - val_loss: 0.2015 - val_accuracy: 0.9574 - val_dice_coef: 0.0516 - val_iou: 0.0270 - val_f1_score: 4.1439e-06\n",
            "Epoch 2/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.9553 - dice_coef: 0.0419 - iou: 0.0218 - f1_score: 0.0000e+00\n",
            "Epoch 2: val_loss improved from 0.20153 to 0.17639, saving model to models/save_best.h5\n",
            "130/130 [==============================] - 154s 1s/step - loss: 0.1768 - accuracy: 0.9553 - dice_coef: 0.0419 - iou: 0.0218 - f1_score: 0.0000e+00 - val_loss: 0.1764 - val_accuracy: 0.9574 - val_dice_coef: 0.0395 - val_iou: 0.0205 - val_f1_score: 0.0000e+00\n",
            "Epoch 3/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9553 - dice_coef: 0.0424 - iou: 0.0221 - f1_score: 0.0000e+00\n",
            "Epoch 3: val_loss did not improve from 0.17639\n",
            "130/130 [==============================] - 145s 1s/step - loss: 0.1743 - accuracy: 0.9553 - dice_coef: 0.0424 - iou: 0.0221 - f1_score: 0.0000e+00 - val_loss: 0.1913 - val_accuracy: 0.9574 - val_dice_coef: 0.0201 - val_iou: 0.0104 - val_f1_score: 0.0000e+00\n",
            "Epoch 4/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.9553 - dice_coef: 0.0426 - iou: 0.0222 - f1_score: 0.0000e+00\n",
            "Epoch 4: val_loss improved from 0.17639 to 0.17479, saving model to models/save_best.h5\n",
            "130/130 [==============================] - 153s 1s/step - loss: 0.1737 - accuracy: 0.9553 - dice_coef: 0.0426 - iou: 0.0222 - f1_score: 0.0000e+00 - val_loss: 0.1748 - val_accuracy: 0.9574 - val_dice_coef: 0.0458 - val_iou: 0.0239 - val_f1_score: 0.0000e+00\n",
            "Epoch 5/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9553 - dice_coef: 0.0431 - iou: 0.0225 - f1_score: 0.0000e+00\n",
            "Epoch 5: val_loss improved from 0.17479 to 0.16861, saving model to models/save_best.h5\n",
            "130/130 [==============================] - 154s 1s/step - loss: 0.1730 - accuracy: 0.9553 - dice_coef: 0.0431 - iou: 0.0225 - f1_score: 0.0000e+00 - val_loss: 0.1686 - val_accuracy: 0.9574 - val_dice_coef: 0.0416 - val_iou: 0.0219 - val_f1_score: 0.0000e+00\n",
            "Epoch 6/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9553 - dice_coef: 0.0442 - iou: 0.0231 - f1_score: 0.0000e+00\n",
            "Epoch 6: val_loss did not improve from 0.16861\n",
            "130/130 [==============================] - 152s 1s/step - loss: 0.1721 - accuracy: 0.9553 - dice_coef: 0.0442 - iou: 0.0231 - f1_score: 0.0000e+00 - val_loss: 0.1802 - val_accuracy: 0.9573 - val_dice_coef: 0.0555 - val_iou: 0.0293 - val_f1_score: 7.3653e-04\n",
            "Epoch 7/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9553 - dice_coef: 0.0448 - iou: 0.0235 - f1_score: 0.0000e+00\n",
            "Epoch 7: val_loss did not improve from 0.16861\n",
            "130/130 [==============================] - 152s 1s/step - loss: 0.1714 - accuracy: 0.9553 - dice_coef: 0.0448 - iou: 0.0235 - f1_score: 0.0000e+00 - val_loss: 0.1732 - val_accuracy: 0.9574 - val_dice_coef: 0.0307 - val_iou: 0.0160 - val_f1_score: 0.0000e+00\n",
            "Epoch 8/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9553 - dice_coef: 0.0462 - iou: 0.0243 - f1_score: 0.0000e+00\n",
            "Epoch 8: val_loss did not improve from 0.16861\n",
            "130/130 [==============================] - 152s 1s/step - loss: 0.1707 - accuracy: 0.9553 - dice_coef: 0.0462 - iou: 0.0243 - f1_score: 0.0000e+00 - val_loss: 0.1868 - val_accuracy: 0.9574 - val_dice_coef: 0.0296 - val_iou: 0.0153 - val_f1_score: 0.0000e+00\n",
            "Epoch 9/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9553 - dice_coef: 0.0467 - iou: 0.0245 - f1_score: 1.5009e-05\n",
            "Epoch 9: val_loss improved from 0.16861 to 0.16821, saving model to models/save_best.h5\n",
            "130/130 [==============================] - 160s 1s/step - loss: 0.1702 - accuracy: 0.9553 - dice_coef: 0.0467 - iou: 0.0245 - f1_score: 1.5009e-05 - val_loss: 0.1682 - val_accuracy: 0.9574 - val_dice_coef: 0.0465 - val_iou: 0.0244 - val_f1_score: 0.0000e+00\n",
            "Epoch 10/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9553 - dice_coef: 0.0484 - iou: 0.0255 - f1_score: 1.7128e-06\n",
            "Epoch 10: val_loss improved from 0.16821 to 0.16751, saving model to models/save_best.h5\n",
            "130/130 [==============================] - 147s 1s/step - loss: 0.1691 - accuracy: 0.9553 - dice_coef: 0.0484 - iou: 0.0255 - f1_score: 1.7128e-06 - val_loss: 0.1675 - val_accuracy: 0.9574 - val_dice_coef: 0.0490 - val_iou: 0.0258 - val_f1_score: 0.0000e+00\n",
            "Epoch 11/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9553 - dice_coef: 0.0504 - iou: 0.0266 - f1_score: 3.9674e-05\n",
            "Epoch 11: val_loss did not improve from 0.16751\n",
            "130/130 [==============================] - 145s 1s/step - loss: 0.1678 - accuracy: 0.9553 - dice_coef: 0.0504 - iou: 0.0266 - f1_score: 3.9674e-05 - val_loss: 0.1685 - val_accuracy: 0.9574 - val_dice_coef: 0.0479 - val_iou: 0.0252 - val_f1_score: 6.0341e-05\n",
            "Epoch 12/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9553 - dice_coef: 0.0527 - iou: 0.0279 - f1_score: 4.3760e-04\n",
            "Epoch 12: val_loss did not improve from 0.16751\n",
            "130/130 [==============================] - 152s 1s/step - loss: 0.1672 - accuracy: 0.9553 - dice_coef: 0.0527 - iou: 0.0279 - f1_score: 4.3760e-04 - val_loss: 0.1801 - val_accuracy: 0.9574 - val_dice_coef: 0.0341 - val_iou: 0.0178 - val_f1_score: 0.0000e+00\n",
            "Epoch 13/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9553 - dice_coef: 0.0573 - iou: 0.0305 - f1_score: 0.0015\n",
            "Epoch 13: val_loss did not improve from 0.16751\n",
            "130/130 [==============================] - 152s 1s/step - loss: 0.1644 - accuracy: 0.9553 - dice_coef: 0.0573 - iou: 0.0305 - f1_score: 0.0015 - val_loss: 0.1785 - val_accuracy: 0.9574 - val_dice_coef: 0.0331 - val_iou: 0.0173 - val_f1_score: 4.5217e-05\n",
            "Epoch 14/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.9553 - dice_coef: 0.0640 - iou: 0.0343 - f1_score: 0.0056\n",
            "Epoch 14: val_loss did not improve from 0.16751\n",
            "130/130 [==============================] - 145s 1s/step - loss: 0.1613 - accuracy: 0.9553 - dice_coef: 0.0640 - iou: 0.0343 - f1_score: 0.0056 - val_loss: 0.1921 - val_accuracy: 0.9574 - val_dice_coef: 0.0299 - val_iou: 0.0160 - val_f1_score: 1.2266e-04\n",
            "Epoch 15/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.9554 - dice_coef: 0.0737 - iou: 0.0398 - f1_score: 0.0165\n",
            "Epoch 15: val_loss did not improve from 0.16751\n",
            "130/130 [==============================] - 152s 1s/step - loss: 0.1567 - accuracy: 0.9554 - dice_coef: 0.0737 - iou: 0.0398 - f1_score: 0.0165 - val_loss: 0.1791 - val_accuracy: 0.9563 - val_dice_coef: 0.0542 - val_iou: 0.0289 - val_f1_score: 0.0173\n",
            "Epoch 16/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9556 - dice_coef: 0.0896 - iou: 0.0491 - f1_score: 0.0523\n",
            "Epoch 16: val_loss did not improve from 0.16751\n",
            "130/130 [==============================] - 153s 1s/step - loss: 0.1504 - accuracy: 0.9556 - dice_coef: 0.0896 - iou: 0.0491 - f1_score: 0.0523 - val_loss: 0.1879 - val_accuracy: 0.9560 - val_dice_coef: 0.0557 - val_iou: 0.0296 - val_f1_score: 0.0154\n",
            "Epoch 17/100\n",
            "130/130 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9562 - dice_coef: 0.1105 - iou: 0.0617 - f1_score: 0.1119\n",
            "Epoch 17: val_loss did not improve from 0.16751\n",
            "130/130 [==============================] - 153s 1s/step - loss: 0.1427 - accuracy: 0.9562 - dice_coef: 0.1105 - iou: 0.0617 - f1_score: 0.1119 - val_loss: 0.1895 - val_accuracy: 0.9569 - val_dice_coef: 0.0345 - val_iou: 0.0182 - val_f1_score: 0.0069\n",
            "Epoch 18/100\n",
            " 28/130 [=====>........................] - ETA: 1:43 - loss: 0.1344 - accuracy: 0.9572 - dice_coef: 0.1323 - iou: 0.0753 - f1_score: 0.1788"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-57bd98af2cfb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train the model while monitoring custom metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m history = model.fit(train_images, train_masks, batch_size=16, epochs=epochs,\n\u001b[0m\u001b[1;32m     10\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     callbacks=[checkpoint])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \"\"\"\n\u001b[1;32m   1065\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing training and testing accuracy\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, epochs + 1)\n",
        "\n",
        "# Plotting\n",
        "plt.plot(epochs, train_accuracy, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KXWBsWwM_xF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'history' object contains the IoU values at each epoch\n",
        "iou_values = history.history['iou']\n",
        "val_iou_values = history.history['val_iou']\n",
        "\n",
        "# Number of epochs\n",
        "epochs = range(1, len(iou_values) + 1)\n",
        "\n",
        "# Plotting the line plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, iou_values, marker='o', linestyle='-', color='r')\n",
        "plt.plot(epochs, val_iou_values, marker='o', linestyle='-', color='b')\n",
        "plt.title('IoU and val_iou across Epochs')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('IoU Value')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kx2nyume_0rP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}